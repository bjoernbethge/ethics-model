{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhgFJfFqhj73"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "N9bX6aIiHY0S"
      },
      "outputs": [],
      "source": [
        "# @title System update\n",
        "%%capture\n",
        "!apt update && apt upgrade -y\n",
        "!uv pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98HCxhTvKutG"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['GIT_TOKEN'] = userdata.get('git_token')\n",
        "os.environ['USER_NAME'] = userdata.get('user_name')\n",
        "os.environ['USER_MAIL'] = userdata.get('user_mail')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Gw37VyQ_Fgmw"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "git config --global user.name \"$USER_NAME\"\n",
        "git config --global user.email \"$USER_MAIL\"\n",
        "git clone https://$GIT_TOKEN@github.com/bjoernbethge/ethics-model.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMFm5knwOWyK"
      },
      "outputs": [],
      "source": [
        "%cd ethics-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma3Ig1qVHOe0"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "uv sync --extra train\n",
        "chmod +x .venv/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oyr1zNTRIFtZ"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "source .venv/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo0YmrDZNDMm"
      },
      "outputs": [],
      "source": [
        "!.venv/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty-htHdAE_ah"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import logging\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from datasets import load_dataset\n",
        "import nlpaug.augmenter.word as naw\n",
        "\n",
        "from ethics_model import EthicsModel\n",
        "from ethics_model.ethics_dataset import EthicsDataset\n",
        "from ethics_model.training import train\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jLM2wGTpJ__"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqXhTNuipPJS"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28615EJEpL0e"
      },
      "outputs": [],
      "source": [
        "# @title  Logging & directories\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "CHECKPOINT_PATH = \"checkpoints/best_ethics_model.pt\"\n",
        "TENSORBOARD_LOGDIR = \"runs/ethics_llm_train\"\n",
        "os.makedirs(os.path.dirname(CHECKPOINT_PATH), exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doB_BcxGp-hR"
      },
      "outputs": [],
      "source": [
        "# @title  LLM & Tokenizer\n",
        "huggingface_model = 'unsloth/gemma-3-4b-it-unsloth-bnb-4bit' # @param {type:\"string\"}\n",
        "bnb_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(huggingface_model)\n",
        "llm = AutoModelForCausalLM.from_pretrained(\n",
        "    huggingface_model,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "llm.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "j58p4dJrA_fh"
      },
      "outputs": [],
      "source": [
        "# @title Model Configuration\n",
        "\n",
        "n_layers = 2  # @param {type:\"integer\", min:1, max:12, step:1}\n",
        "n_heads = 8  # @param {type:\"integer\", min:1, max:16, step:1}\n",
        "max_seq_length = 128  # @param {type:\"integer\", min:64, max:512, step:64}\n",
        "activation = 'gelu'  # @param [\"gelu\", \"relu\", \"tanh\"]\n",
        "use_gnn = False  # @param {type:\"boolean\"}\n",
        "\n",
        "model = EthicsModel(\n",
        "    gnn_hidden_dim=llm.config.hidden_size,\n",
        "    num_gnn_layers=n_layers,\n",
        "    gnn_num_heads=n_heads,\n",
        "    activation=activation\n",
        ").to(DEVICE)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sumxbfa4vY0w"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8MSkTJmsNeP"
      },
      "outputs": [],
      "source": [
        "# @title  Augmentation\n",
        "\n",
        "aug = naw.SynonymAug(aug_src='wordnet')\n",
        "def synonym_augment(text):\n",
        "    try:\n",
        "        return aug.augment(text)\n",
        "    except Exception:\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqs_RYZTAoBp"
      },
      "outputs": [],
      "source": [
        "# @title  Preparation\n",
        "\n",
        "ds = load_dataset(\"flozi00/Fineweb2-German-Eduscore-4andMore\", split=\"train[:1000]\")\n",
        "texts = ds[\"text\"]\n",
        "ethics_labels = [float(x) for x in ds[\"eduscore\"]]\n",
        "manipulation_labels = [float(x) for x in ds[\"manipulation_score\"]] if \"manipulation_score\" in ds.column_names else ethics_labels\n",
        "\n",
        "dataset = EthicsDataset(\n",
        "    texts, ethics_labels, manipulation_labels, tokenizer,\n",
        "    max_length=max_seq_length,\n",
        "    augment=True, synonym_augment=synonym_augment\n",
        ")\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOtLiXzBBpri"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5AxmBbR5BwZY"
      },
      "outputs": [],
      "source": [
        "# @title  Training\n",
        "writer = SummaryWriter(log_dir=TENSORBOARD_LOGDIR)\n",
        "model_trained = train(model, llm, dataloader, optimizer, criterion, writer, DEVICE)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fKoLpfCvCJ5F"
      },
      "outputs": [],
      "source": [
        "        # @title  Evaluation\n",
        "def evaluate(model, llm, dataloader, tokenizer, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            ethics_label = batch['ethics_label'].to(device)\n",
        "            manipulation_label = batch['manipulation_label'].to(device)\n",
        "            llm_outputs = llm.model.transformer(input_ids) if hasattr(llm, 'model') else llm.transformer(input_ids)\n",
        "            hidden_states = llm_outputs.last_hidden_state\n",
        "            outputs = model(embeddings=hidden_states, attention_mask=attention_mask)\n",
        "            ethics_score = outputs['ethics_score']\n",
        "            manipulation_score = outputs['manipulation_score']\n",
        "            logger.info(f\"Text: {tokenizer.batch_decode(input_ids, skip_special_tokens=True)}\")\n",
        "            logger.info(f\"Ethics Score: {ethics_score.squeeze(-1).cpu().numpy()} | Label: {ethics_label.squeeze(-1).cpu().numpy()}\")\n",
        "            logger.info(f\"Manipulation Score: {manipulation_score.squeeze(-1).cpu().numpy()} | Label: {manipulation_label.squeeze(-1).cpu().numpy()}\")\n",
        "\n",
        "evaluate(model_trained, llm, dataloader, tokenizer, DEVICE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
