{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "uhgFJfFqhj73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!apt update && apt upgrade -y\n",
        "!uv pip install --upgrade pip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N9bX6aIiHY0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['GIT_TOKEN'] = userdata.get('git_token')\n",
        "os.environ['USER_NAME'] = userdata.get('user_name')\n",
        "os.environ['USER_MAIL'] = userdata.get('user_mail')"
      ],
      "metadata": {
        "id": "98HCxhTvKutG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "git config --global user.name \"$USER_NAME\"\n",
        "git config --global user.email \"$USER_MAIL\"\n",
        "git clone https://$GIT_TOKEN@github.com/bjoernbethge/ethics-model.git\n",
        "cd ethics-model\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Gw37VyQ_Fgmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ethics-model"
      ],
      "metadata": {
        "id": "TMFm5knwOWyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "uv sync --extra train\n"
      ],
      "metadata": {
        "id": "ma3Ig1qVHOe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AOqX40utm9Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuer Abschnitt"
      ],
      "metadata": {
        "id": "hbpjsp1vh1s8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# ===== CUDA & bitsandbytes ENV VARS =====\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"8.0\" # for A100\n",
        "os.environ[\"BNB_CUDA_VERSION\"] = \"121\"\n",
        "\n",
        "import copy\n",
        "import random\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from datasets import load_dataset\n",
        "import nlpaug.augmenter.word as naw\n",
        "\n",
        "from ethics_model.ethics import EthicsModel\n",
        "\n",
        "# =====================\n",
        "# 1. Configuration & Logging\n",
        "# =====================\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "CHECKPOINT_PATH = \"checkpoints/best_ethics_model.pt\"\n",
        "TENSORBOARD_LOGDIR = \"runs/ethics_llm_train\"\n",
        "os.makedirs(os.path.dirname(CHECKPOINT_PATH), exist_ok=True)\n",
        "\n",
        "# =====================\n",
        "# 2. LLM & Tokenizer Setup\n",
        "# =====================\n",
        "bnb_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\")\n",
        "llm = AutoModelForCausalLM.from_pretrained(\n",
        "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "llm.eval()\n",
        "\n",
        "# =====================\n",
        "# 3. Data Augmentation\n",
        "# =====================\n",
        "aug = naw.SynonymAug(aug_src='wordnet')\n",
        "def synonym_augment(text):\n",
        "    try:\n",
        "        return aug.augment(text)\n",
        "    except Exception:\n",
        "        return text\n",
        "\n",
        "# =====================\n",
        "# 4. Dataset Preparation\n",
        "# =====================\n",
        "ds = load_dataset(\"flozi00/Fineweb2-German-Eduscore-4andMore\", split=\"train[:1000]\")\n",
        "texts = ds[\"text\"]\n",
        "ethics_labels = [float(x) for x in ds[\"eduscore\"]]\n",
        "manipulation_labels = [float(x) for x in ds[\"manipulation_score\"]] if \"manipulation_score\" in ds.column_names else ethics_labels\n",
        "\n",
        "class MultiTaskDataset(Dataset):\n",
        "    def __init__(self, texts, ethics_labels, manipulation_labels, tokenizer, max_length=128, augment=False):\n",
        "        self.texts = texts\n",
        "        self.ethics_labels = ethics_labels\n",
        "        self.manipulation_labels = manipulation_labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.augment = augment\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        if self.augment and random.random() < 0.3:\n",
        "            text = synonym_augment(text)\n",
        "        inputs = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, truncation=True, padding='max_length')\n",
        "        item = {k: v.squeeze(0) for k, v in inputs.items()}\n",
        "        item['ethics_label'] = torch.tensor([self.ethics_labels[idx]], dtype=torch.float32)\n",
        "        item['manipulation_label'] = torch.tensor([self.manipulation_labels[idx]], dtype=torch.float32)\n",
        "        return item\n",
        "\n",
        "# =====================\n",
        "# 5. Model & Training Setup\n",
        "# =====================\n",
        "model_config = {\n",
        "    'input_dim': llm.config.hidden_size,\n",
        "    'd_model': llm.config.hidden_size,\n",
        "    'n_layers': 2,\n",
        "    'n_heads': 8,\n",
        "    'vocab_size': tokenizer.vocab_size,\n",
        "    'max_seq_length': 128,\n",
        "    'activation': 'gelu',\n",
        "    'use_gnn': False\n",
        "}\n",
        "\n",
        "# =====================\n",
        "# 6. Training & Evaluation Functions\n",
        "# =====================\n",
        "def train(model, llm, dataloader, optimizer, criterion, writer, device, epochs=10, patience=2):\n",
        "    best_loss = float('inf')\n",
        "    best_model = None\n",
        "    patience_counter = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        total_ethics, total_manip, n_batches = 0.0, 0.0, 0\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            ethics_label = batch['ethics_label'].to(device)\n",
        "            manipulation_label = batch['manipulation_label'].to(device)\n",
        "            with torch.no_grad():\n",
        "                llm_outputs = llm.model.transformer(input_ids) if hasattr(llm, 'model') else llm.transformer(input_ids)\n",
        "                hidden_states = llm_outputs.last_hidden_state\n",
        "            outputs = model(embeddings=hidden_states, attention_mask=attention_mask)\n",
        "            ethics_score = outputs['ethics_score']\n",
        "            manipulation_score = outputs['manipulation_score']\n",
        "            loss_ethics = criterion(ethics_score, ethics_label)\n",
        "            loss_manip = criterion(manipulation_score, manipulation_label)\n",
        "            loss = loss_ethics + 0.5 * loss_manip\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * input_ids.size(0)\n",
        "            total_ethics += loss_ethics.item() * input_ids.size(0)\n",
        "            total_manip += loss_manip.item() * input_ids.size(0)\n",
        "            n_batches += input_ids.size(0)\n",
        "        avg_loss = total_loss / len(dataloader.dataset)\n",
        "        avg_ethics = total_ethics / len(dataloader.dataset)\n",
        "        avg_manip = total_manip / len(dataloader.dataset)\n",
        "        logger.info(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} | Ethics: {avg_ethics:.4f} | Manip: {avg_manip:.4f}\")\n",
        "        writer.add_scalar('Loss/Total', avg_loss, epoch+1)\n",
        "        writer.add_scalar('Loss/Ethics', avg_ethics, epoch+1)\n",
        "        writer.add_scalar('Loss/Manipulation', avg_manip, epoch+1)\n",
        "        # Early Stopping & Checkpoint\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "            patience_counter = 0\n",
        "            torch.save(best_model, CHECKPOINT_PATH)\n",
        "            logger.info(f\"Checkpoint saved: {CHECKPOINT_PATH}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                logger.info(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "    if best_model is not None:\n",
        "        model.load_state_dict(best_model)\n",
        "    return model\n",
        "\n",
        "def evaluate(model, llm, dataloader, tokenizer, writer, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            ethics_label = batch['ethics_label'].to(device)\n",
        "            manipulation_label = batch['manipulation_label'].to(device)\n",
        "            llm_outputs = llm.model.transformer(input_ids) if hasattr(llm, 'model') else llm.transformer(input_ids)\n",
        "            hidden_states = llm_outputs.last_hidden_state\n",
        "            outputs = model(embeddings=hidden_states, attention_mask=attention_mask)\n",
        "            ethics_score = outputs['ethics_score']\n",
        "            manipulation_score = outputs['manipulation_score']\n",
        "            logger.info(f\"Text: {tokenizer.batch_decode(input_ids, skip_special_tokens=True)}\")\n",
        "            logger.info(f\"Ethics Score: {ethics_score.squeeze(-1).cpu().numpy()} | Label: {ethics_label.squeeze(-1).cpu().numpy()}\")\n",
        "            logger.info(f\"Manipulation Score: {manipulation_score.squeeze(-1).cpu().numpy()} | Label: {manipulation_label.squeeze(-1).cpu().numpy()}\")\n",
        "            writer.add_scalar('Eval/EthicsScore', ethics_score.mean().item(), 0)\n",
        "            writer.add_scalar('Eval/ManipScore', manipulation_score.mean().item(), 0)\n",
        "\n",
        "# =====================\n",
        "# 7. Main\n",
        "# =====================\n",
        "def main():\n",
        "    writer = SummaryWriter(log_dir=TENSORBOARD_LOGDIR)\n",
        "    dataset = MultiTaskDataset(texts, ethics_labels, manipulation_labels, tokenizer, augment=True)\n",
        "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "    model = EthicsModel(**model_config).to(DEVICE)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    model = train(model, llm, dataloader, optimizer, criterion, writer, DEVICE)\n",
        "    evaluate(model, llm, dataloader, tokenizer, writer, DEVICE)\n",
        "    writer.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "ty-htHdAE_ah"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}